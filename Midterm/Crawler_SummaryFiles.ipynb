{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_file(url, local_filename):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024): \n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basicUrl = 'https://freddiemac.embs.com'\n",
    "basicSecureUrl = basicUrl + '/FLoan/secure/'\n",
    "loginPageUrl = basicSecureUrl + 'login.php'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with requests.session() as s:\n",
    "    # Login Page Get\n",
    "    request = s.get(loginPageUrl)\n",
    "    loginPageSoup = BeautifulSoup(request.text, 'lxml')\n",
    "    \n",
    "    # Login Post\n",
    "    loginPostUrl = basicSecureUrl + loginPageSoup.find_all('form')[0]['action']\n",
    "    payload = {}\n",
    "    payload['username'] = 'liu.jiah@husky.neu.edu'\n",
    "    payload['password'] = 'AK~JihFG'\n",
    "    response = s.post(loginPostUrl, data=payload)\n",
    "    TandCSoup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "    # T and C Post\n",
    "    downloadUrl = basicUrl + TandCSoup.find_all('form')[0]['action']\n",
    "    payload = {}\n",
    "    payload['accept'] = 'Yes'\n",
    "    payload['acceptSubmit'] = 'Continue'\n",
    "    payload['action'] = 'acceptTandC'\n",
    "    response = s.post(downloadUrl, data=payload)\n",
    "    downloadPageSoup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "#     print(downloadPageSoup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = []\n",
    "\n",
    "# Download Files Get\n",
    "for elem in downloadPageSoup.find_all('a'):\n",
    "    filename = elem.get_text()\n",
    "    url = 'https://freddiemac.embs.com/FLoan/Data/' + filename\n",
    "    year = filename[-8:-4]\n",
    "    quarter = filename\n",
    "#     if filename.startswith('sample') and int(year) == 2005:\n",
    "    if filename.startswith('historical') and int(year) == 2010:\n",
    "        filenames.append(filename)\n",
    "        download_file(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unzip file\n",
    "for file in filenames:\n",
    "    with zipfile.ZipFile(file,\"r\") as zip_ref:\n",
    "        zip_ref.extractall(file.split('.')[0])\n",
    "        zip_ref.close()\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Summary Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from random import randint, random\n",
    "from numbers import Number\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Orig File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuji\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (0,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "C:\\Users\\liuji\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (0,5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "for year in [1999, 2013]:\n",
    "    for quarter in range(1, 5):\n",
    "        orig_file = 'historical_data1_Q{0}{1}/historical_data1_Q{0}{1}.txt'.format(quarter, year)\n",
    "        orig_clean_file = 'historical_data1_Q{0}{1}/historical_data1_Q{0}{1}_clean.csv'.format(quarter, year)\n",
    "        orig_df = cleanOrigData(orig_file, orig_clean_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Perf File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuji\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (3,7,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "for year in range(2009, 2010):\n",
    "    for quarter in range(2, 5):\n",
    "        perf_file = 'historical_data1_Q{0}{1}/historical_data1_time_Q{0}{1}.txt'.format(quarter, year)\n",
    "        perf_clean_file = 'historical_data1_Q{0}{1}/historical_data1_time_Q{0}{1}_clean.csv'.format(quarter, year)\n",
    "        perf_df = cleanPerfData(perf_file, perf_clean_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calMean(df, col):\n",
    "    std = df[col].std()\n",
    "    mean = df[col].mean()\n",
    "    left = mean - 1.5 * std\n",
    "    right = mean + 1.5 * std\n",
    "    realMean = df[(df[col] > left) & (df[col] < right)][col].mean()\n",
    "    return realMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanOrigData(orig_file, clean_file):\n",
    "    orig_col_headers = ['credit_score', 'first_payment_date', 'first_time_homebuyer_flag', 'maturity_date', 'metropolitan_stat_area', 'mortgage_insurance_perc', 'no_unit', 'occupancy_status', 'orig_combined_loantovalue', 'orig_debttoincome', 'orig_upb', 'orig_loantovalue', 'orig_interest_rate', 'channel', 'prepayment_penalty_mortgage_flag', 'product_type', 'property_state', 'property_type', 'postal_code', 'loan_sequence_no', 'loan_purpose', 'orig_loan_term', 'no_borrower', 'seller_name', 'service_name', 'super_conforming_flag']\n",
    "    orig_df = pd.read_csv(orig_file, sep='|', names=orig_col_headers)\n",
    "    \n",
    "    if not np.issubdtype(orig_df['credit_score'].dtype, np.number):\n",
    "        orig_df.loc[orig_df['credit_score'] == \"   \", 'credit_score'] = 300\n",
    "    orig_df['credit_score'] = orig_df['credit_score'].astype(int)\n",
    "    \n",
    "    if not np.issubdtype(orig_df['orig_debttoincome'].dtype, np.number):\n",
    "        for ind, row in orig_df.iterrows():\n",
    "            if row['orig_debttoincome'] == \"   \":\n",
    "                orig_df.iloc[ind, orig_df.columns.get_loc('orig_debttoincome')] = randint(65, 70)\n",
    "                \n",
    "    new_df = orig_df[orig_df['orig_debttoincome'].apply(lambda x: isinstance(x, Number))]\n",
    "    mean = calMean(new_df, 'orig_debttoincome')\n",
    "    orig_df['orig_debttoincome'] = orig_df['orig_debttoincome'].fillna(mean).astype(int)\n",
    "    \n",
    "    orig_df['first_time_homebuyer_flag'] = orig_df['first_time_homebuyer_flag'].fillna('N')\n",
    "    \n",
    "    orig_df['metropolitan_stat_area'] = orig_df['metropolitan_stat_area'].fillna(0)\n",
    "    \n",
    "    orig_df['no_unit'] = orig_df['no_unit'].fillna(1)\n",
    "    \n",
    "    mode = orig_df['orig_combined_loantovalue'].mode()[0]\n",
    "    new_df = orig_df[orig_df['orig_combined_loantovalue'] != mode]\n",
    "    mean = calMean(new_df, 'orig_combined_loantovalue')\n",
    "    orig_df['orig_combined_loantovalue'] = orig_df['orig_combined_loantovalue'].fillna(mean).astype(int)\n",
    "        \n",
    "    mode = orig_df['orig_loantovalue'].mode()[0]\n",
    "    new_df = orig_df[orig_df['orig_loantovalue'] != mode]\n",
    "    mean = calMean(new_df, 'orig_loantovalue')\n",
    "    orig_df['orig_loantovalue'] = orig_df['orig_loantovalue'].fillna(mean).astype(int)\n",
    "    \n",
    "    orig_df['prepayment_penalty_mortgage_flag'] = orig_df['prepayment_penalty_mortgage_flag'].fillna('N')\n",
    "    \n",
    "    orig_df['postal_code'] = orig_df['postal_code'].fillna('00000')\n",
    "    \n",
    "    one_borrower_perc = orig_df['no_borrower'].value_counts()[1.0] / orig_df.shape[0]\n",
    "    temp_df = orig_df[orig_df['no_borrower'] != orig_df['no_borrower']]\n",
    "    for ind, row in temp_df.iterrows():\n",
    "        orig_df.iloc[ind, orig_df.columns.get_loc('no_borrower')] = 1 if random() < one_borrower_perc else 2\n",
    "    \n",
    "    if not np.issubdtype(orig_df['mortgage_insurance_perc'].dtype, np.number):\n",
    "        orig_df.loc[orig_df['mortgage_insurance_perc'] == \"   \", 'mortgage_insurance_perc'] = 0\n",
    "        orig_df.loc[orig_df['mortgage_insurance_perc'] == \"000\", 'mortgage_insurance_perc'] = 0\n",
    "    \n",
    "    orig_df = orig_df.drop('super_conforming_flag', 1)\n",
    "    \n",
    "    orig_df.to_csv(clean_file, index=False)\n",
    "\n",
    "    return orig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanPerfData(perf_file, clean_file):\n",
    "    perform_col_headers = ['loan_sequence_no', 'monthly_reporting_period', 'curr_actual_upb', 'curr_loan_delinquency_status', 'loan_age', 'remaining_months_to_legal_maturity', 'repurchase_flag', 'modification_flag', 'zero_balance_code', 'zero_balance_effective_date', 'curr_interest_rate', 'curr_deferred_upb', 'due_date_last_paid_installment', 'mi_recoveries', 'net_sales_proceeds', 'non_mi_recoveries', 'expenses', 'legal_costs', 'maintain_preserve_costs', 'tax_insurance', 'miscellaneous_expense', 'actual_loss_calculation', 'modification_cost']\n",
    "    perf_df = pd.read_csv(perf_file, sep='|', names=perform_col_headers)\n",
    "    \n",
    "    missing_df = perf_df.isnull().sum(axis=0).reset_index()\n",
    "    missing_df.columns = ['col', 'missing_cnt']\n",
    "    missing_df = missing_df[missing_df['missing_cnt'] > 0]\n",
    "    \n",
    "    colsToDrop = missing_df['col'].tolist()\n",
    "    colsToDrop.remove('actual_loss_calculation')\n",
    "    perf_df = perf_df.drop(colsToDrop, axis=1)\n",
    "    \n",
    "    perf_df.to_csv(clean_file, index=False)\n",
    "\n",
    "    return perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Summary Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuji\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (3,7,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "C:\\Users\\liuji\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "C:\\Users\\liuji\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "C:\\Users\\liuji\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (3,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "C:\\Users\\liuji\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "C:\\Users\\liuji\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (0,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "C:\\Users\\liuji\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "C:\\Users\\liuji\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (3,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "C:\\Users\\liuji\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "orig_summary_list = []\n",
    "orig_summary_state_list = []\n",
    "perf_summary_list = []\n",
    "\n",
    "for year in range(2005, 2017):\n",
    "    \n",
    "    # Origination Summary File By Year\n",
    "    \n",
    "    orig_file = 'sample_{0}/sample_orig_{0}.txt'.format(year)\n",
    "    orig_clean_file = 'sample_{0}/sample_orig_{0}_clean.csv'.format(year)\n",
    "    \n",
    "    orig_df = cleanOrigData(orig_file, orig_clean_file)\n",
    " \n",
    "    orig_summary_dict = OrderedDict()\n",
    "    \n",
    "    orig_summary_dict['year'] = year\n",
    "    \n",
    "    loanCount = np.count_nonzero(orig_df['loan_sequence_no'])\n",
    "    orig_summary_dict['loanCount'] = loanCount\n",
    "    \n",
    "    totalOrigUPB = orig_df['orig_upb'].sum()\n",
    "    orig_summary_dict['totalOrigUPB'] = totalOrigUPB\n",
    "    \n",
    "    avgOrigUPB = orig_df['orig_upb'].mean()\n",
    "    orig_summary_dict['avgOrigUPB'] = avgOrigUPB\n",
    "    \n",
    "    avgCreditScore = orig_df[orig_df['credit_score'] > 0]['credit_score'].mean()\n",
    "    orig_summary_dict['avgCreditScore'] = avgCreditScore\n",
    "    \n",
    "    avgOrigInterestRate = orig_df['orig_interest_rate'].mean()\n",
    "    orig_summary_dict['avgOrigInterestRate'] = avgOrigInterestRate\n",
    "    \n",
    "    avgOrigCombinedLoantovalue = orig_df['orig_combined_loantovalue'].mean()\n",
    "    orig_summary_dict['avgOrigCombinedLoantovalue'] = avgOrigCombinedLoantovalue\n",
    "    \n",
    "    avgOrigLoantovalue = orig_df['orig_loantovalue'].mean()\n",
    "    orig_summary_dict['avgOrigLoantovalue'] = avgOrigLoantovalue\n",
    "    \n",
    "    avgOrigDebttoincome = orig_df['orig_debttoincome'].mean()\n",
    "    orig_summary_dict['avgOrigDebttoincome'] = avgOrigDebttoincome\n",
    "    \n",
    "    orig_summary_list.append(orig_summary_dict)\n",
    "    \n",
    "    # Origination Summary File By State\n",
    "    \n",
    "    for state in orig_df['property_state'].unique():\n",
    "        \n",
    "        orig_summary_state_dict = OrderedDict()\n",
    "    \n",
    "        orig_summary_state_dict['year'] = year\n",
    "    \n",
    "        orig_summary_state_dict['state'] = state\n",
    "        \n",
    "        loanCount = np.count_nonzero(orig_df[orig_df['property_state'] == state]['loan_sequence_no'])\n",
    "        orig_summary_state_dict['loanCount'] = loanCount\n",
    "        \n",
    "        totalOrigUPB = orig_df[orig_df['property_state'] == state]['orig_upb'].sum()\n",
    "        orig_summary_state_dict['totalOrigUPB'] = totalOrigUPB\n",
    "\n",
    "        avgOrigUPB = orig_df[orig_df['property_state'] == state]['orig_upb'].mean()\n",
    "        orig_summary_state_dict['avgOrigUPB'] = avgOrigUPB\n",
    "\n",
    "        avgCreditScore = orig_df[(orig_df['property_state'] == state) & (orig_df['credit_score'] > 0)]['credit_score'].mean()\n",
    "        orig_summary_state_dict['avgCreditScore'] = avgCreditScore\n",
    "\n",
    "        avgOrigInterestRate = orig_df[orig_df['property_state'] == state]['orig_interest_rate'].mean()\n",
    "        orig_summary_state_dict['avgOrigInterestRate'] = avgOrigInterestRate\n",
    "\n",
    "        avgOrigCombinedLoantovalue = orig_df[orig_df['property_state'] == state]['orig_combined_loantovalue'].mean()\n",
    "        orig_summary_state_dict['avgOrigCombinedLoantovalue'] = avgOrigCombinedLoantovalue\n",
    "\n",
    "        avgOrigLoantovalue = orig_df[orig_df['property_state'] == state]['orig_loantovalue'].mean()\n",
    "        orig_summary_state_dict['avgOrigLoantovalue'] = avgOrigLoantovalue\n",
    "\n",
    "        avgOrigDebttoincome = orig_df[orig_df['property_state'] == state]['orig_debttoincome'].mean()\n",
    "        orig_summary_state_dict['avgOrigDebttoincome'] = avgOrigDebttoincome\n",
    "        \n",
    "        orig_summary_state_list.append(orig_summary_state_dict)\n",
    "    \n",
    "    # Performance Summary File\n",
    "    \n",
    "    perf_file = 'sample_{0}/sample_svcg_{0}.txt'.format(year)\n",
    "    perf_clean_file = 'sample_{0}/sample_svcg_{0}_clean.csv'.format(year)\n",
    "    \n",
    "    perf_df = cleanPerfData(perf_file, perf_clean_file)\n",
    "    \n",
    "    perf_summary_dict = OrderedDict()\n",
    "    \n",
    "    perf_summary_dict['year'] = year\n",
    "    \n",
    "#     loanCount = np.count_nonzero(perf_df['loan_sequence_no'].unique())\n",
    "#     perf_summary_dict['loanCount'] = loanCount\n",
    "    \n",
    "#     totalCurrActualUpb = perf_df['curr_actual_upb'].sum()\n",
    "#     perf_summary_dict['totalCurrActualUpb'] = totalCurrActualUpb\n",
    "    \n",
    "#     avgCurrActualUpb = perf_df['curr_actual_upb'].mean()\n",
    "#     perf_summary_dict['avgCurrActualUpb'] = avgCurrActualUpb\n",
    "    \n",
    "    perf_df['curr_loan_delinquency_status'] = perf_df['curr_loan_delinquency_status'].astype(str)\n",
    "    nonDelinquencyRatio = perf_df[perf_df['curr_loan_delinquency_status'] == '0']['curr_loan_delinquency_status'].count() / perf_df.shape[0]\n",
    "    perf_summary_dict['nonDelinquencyRatio'] = nonDelinquencyRatio\n",
    "    \n",
    "    interest_rate_df = perf_df.groupby(['loan_sequence_no'])['curr_interest_rate'].mean().reset_index()\n",
    "    avgCurrInterestRate = interest_rate_df['curr_interest_rate'].mean()\n",
    "    perf_summary_dict['avgCurrInterestRate'] = avgCurrInterestRate\n",
    "    \n",
    "    perf_summary_list.append(perf_summary_dict)\n",
    "    \n",
    "orig_summary_df = pd.DataFrame(orig_summary_list)\n",
    "orig_summary_df.to_csv('orig_summary.csv', index=False)\n",
    "\n",
    "orig_summary_state_df = pd.DataFrame(orig_summary_state_list)\n",
    "orig_summary_state_df.to_csv('orig_summary_state.csv', index=False)\n",
    "\n",
    "perf_summary_df = pd.DataFrame(perf_summary_list)\n",
    "perf_summary_df.to_csv('perf_summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
